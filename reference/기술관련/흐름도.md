욜로 모델 학습 플로우
---
    학습 데이터 (이미지 & 라벨)
        ↓
    YOLO 모델 학습
        ↓
    학습된 가중치 (best.pt)
        ↓
    실시간 영상 → 프레임 단위로 YOLO 탐지 → 탐지 결과를 시각화하여 화면 출력

※ 한번만 학습시키면 best.pt(학습된 가중치 파일)을 만들어서 모델 선언 때 재사용 하면 되기 때문에,
학습은 한번만 해도 된다?
<details>
<summary>욜로 학습 코드</summary>

```
pip install ultralytics
```
데이터 구성 정의: dataset.yaml
```
path: ./datasets               # 데이터셋 루트 경로
train: images/train            # 학습용 이미지 경로
val: images/val                # 검증용 이미지 경로
test: images/test              # 테스트용 이미지 경로 (선택)
nc: 2                          # 클래스 개수 (예: 2개 클래스)
names: ['cat', 'dog']          # 클래스 이름
```
fine-tunning
```
from ultralytics import YOLO

# YOLOv8 모델 로드
model = YOLO('yolov8n.pt')  # 'n'은 가장 가벼운 모델 (n, s, m, l, x 옵션)

# 모델 학습
model.train(data='custom_dataset.yaml', epochs=50, imgsz=640)
```
모델테스트
```
# 학습된 모델 로드
model = YOLO('runs/detect/train/best.pt')

# 이미지에서 테스트
results = model('test_image.jpg', show=True)

# 비디오에서 테스트
model('test_video.mp4', show=True)
```
모델 배포
```
model.export(format='onnx')  # 또는 'engine' (TensorRT)
```
</details>

Yolo 리턴값
---
    [
    [x1, y1, x2, y2, confidence, class_id],
    [x1, y1, x2, y2, confidence, class_id],
    ...
    ]
```
x1,y1: 바운딩 박스의 왼쪽 위 좌표
x2,y2: 바운딩 박스의 오른쪽 아래 좌표
confidence: 신뢰도 점수
class_id: 클래스 ID
```




전체 흐름
---
1. 프레임 캡처
- 카메라(웹캠, RTSP 스트림 등)에서 실시간으로 한 프레임을 가져온다.
- cv2.VideoCapture를 사용하거나, RTSP를 통해 영상 스트림을 읽는다다.

2. 객체 탐지
- 가져온 프레임을 YOLO 모델에 입력한다.
- YOLO는 객체의 위치(바운딩 박스), 클래스 정보(이름), 신뢰도를 반환한다.

3. 탐지 결과 오버레이
- YOLO의 리턴값(바운딩 박스, 클래스 이름, 신뢰도)을 활용해 프레임에 정보를 오버레이한다:
    - 바운딩 박스 그리기: cv2.rectangle
    - 클래스 이름과 신뢰도 표시: cv2.putText

4. 수정된 프레임 출력
- 수정된 프레임을 cv2.imshow를 통해 화면에 실시간으로 출력한다.

5. 동작 방식 요약<br>
클라이언트에서 영상 캡처 → 서버로 전송.
서버에서 YOLO 모델로 객체 탐지 수행.
탐지 결과를 오버레이하여 수정된 프레임 생성.
서버에서 수정된 프레임을 클라이언트로 반환하거나, 바로 화면에 출력.


# 프로젝트 전체 프로세스 (A to Z)

<details>

<summary>도커에 대한 이해</summary>

※Docker란?
- docker는 컨테이너화를 통해 어플리케이션이 가상환경에서 실행되게 하기 위해
- 일괄된 실행 환경을 제공하기 위해
```
이미지(Image):
실행 가능한 애플리케이션과 환경 설정이 포함된 템플릿.
예: Python 애플리케이션을 실행하기 위한 Python 환경이 포함된 이미지.

컨테이너(Container):
이미지를 기반으로 실행되는 독립된 프로세스.
컨테이너 = 이미지 + 실행 상태.
예: Python 코드가 동작하는 실행 중인 환경.

Dockerfile:
컨테이너 이미지를 만드는 설정 파일.
이미지 생성에 필요한 지침(명령어) 목록.

Docker Compose:
여러 개의 컨테이너를 한 번에 실행하고 관리할 수 있는 도구.
```
도커 컴포스로 - 도커를 실행 (파이썬 도커, 자바 도커, 웹 도커)
도커는 Dockerfile(메타데이터) 를 기반으로 실행이 됨.

```
FROM:

컨테이너의 기반 환경을 지정.
예: Python 애플리케이션의 경우 Python 이미지를 기반으로 사용.
WORKDIR:

컨테이너 내부에서 작업할 디렉토리를 지정.
모든 명령어가 이 디렉토리에서 실행됩니다.
COPY:

로컬 파일을 컨테이너 내부로 복사.
예: 애플리케이션 코드, 라이브러리 등을 컨테이너로 복사.
RUN:

컨테이너 이미지를 빌드할 때 실행되는 명령어.
예: 라이브러리 설치, 설정 파일 생성.
CMD:

컨테이너가 실행될 때 수행할 기본 명령어를 지정.
예: Python 스크립트 실행.
```
프론트는 REST API 요청만 담당

</details>


---

이 문서는 **프론트엔드, 백엔드(Spring Boot), Python 백엔드(Flask)**, 그리고 **Nginx**를 포함한 프로젝트의 전체 프로세스를 다룹니다. 각 단계는 설정, 구현, 실행 순으로 설명되며, **데이터 흐름**, **LangChain RAG 구성**, **크로마 DB 연동**, **Ollama AI 연동**과 같은 고급 기능까지 포함합니다.

---

## 1. 프로젝트 디렉토리 구조

```
project/
├── backend/                        # Spring Boot 백엔드
│   ├── src/main/java/
│   │   ├── com.example.demo/
│   │   │   ├── DemoApplication.java    # Spring Boot 메인 클래스
│   │   │   ├── controller/
│   │   │   │   ├── AuthController.java # 인증 및 로그인 관련 컨트롤러
│   │   │   │   └── PageController.java # 데이터 제공 컨트롤러
│   │   │   ├── service/
│   │   │   │   └── AuthService.java    # 인증 로직 처리
│   │   │   ├── model/
│   │   │   │   └── User.java           # 사용자 모델
│   ├── src/main/resources/
│   │   ├── application.properties      # Spring Boot 설정 파일
│   ├── Dockerfile                      # Spring Boot Dockerfile
│   ├── pom.xml                         # Maven 설정 파일
├── python-backend/                 # Python 백엔드
│   ├── app.py                         # Flask 메인 애플리케이션
│   ├── chromadb_manager.py            # Chroma DB 관리 스크립트
│   ├── requirements.txt               # Python 의존성 목록
│   ├── ollama_manager.py              # Ollama API 연동 스크립트
│   ├── Dockerfile                     # Python Dockerfile
├── frontend/                        # 프론트엔드 정적 파일
│   ├── index.html                     # 메인 페이지
│   ├── main.html                      # 메인 콘텐츠 페이지
│   ├── profile.html                   # 프로필 페이지
│   ├── scripts/                       # JavaScript 파일 디렉토리
│   │   ├── login.js                   # 로그인 처리 JS
│   │   ├── main.js                    # 메인 페이지 데이터 로드 JS
│   │   └── profile.js                 # 프로필 데이터 로드 JS
│   ├── styles/                        # CSS 파일 디렉토리
│   │   ├── styles.css                 # 공통 스타일
│   ├── Dockerfile                     # Nginx를 활용한 프론트엔드 Dockerfile
├── nginx/                           # Nginx 설정 파일 디렉토리
│   ├── nginx.conf                     # Nginx 설정 파일
├── docker-compose.yml               # Docker Compose 설정 파일
```

---

## 2. 데이터 흐름 (Flow)

### 2.1. 사용자 흐름
1. 사용자가 브라우저에서 `http://frontend-domain.com`에 접속.
2. **프론트엔드**가 `index.html` 파일을 제공.
3. 사용자가 로그인 폼에 아이디/비밀번호 입력 → JavaScript가 **Axios**를 통해 백엔드(Spring Boot)에 API 요청.
4. **Spring Boot**가 사용자를 인증하고, 세션을 생성하여 브라우저에 쿠키로 전달.
5. 사용자가 질문을 입력하면 프론트엔드가 Java 백엔드로 API 요청 → **Java 백엔드가 Python 백엔드**로 질문 전달.
6. **Python 백엔드**가 질문을 처리하고, 필요 시 **Ollama**를 호출하여 결과를 생성.
7. **Python 백엔드**에서 결과를 반환 (LangChain 및 Chroma DB 활용 포함).
8. **Java 백엔드**는 결과를 프론트엔드로 전달.
9. 프론트엔드가 데이터를 화면에 렌더링.

### 2.2. 기술 간 상호작용
#### 데이터 흐름 요약
- **프론트엔드 ↔ 백엔드(Spring Boot)**
  - 요청: Axios를 사용하여 REST API 호출.
  - 응답: JSON 형식으로 데이터를 반환.

- **백엔드(Spring Boot) ↔ Python 백엔드**
  - 요청: Spring Boot가 RestTemplate으로 HTTP 요청 전송.
  - 응답: Python 백엔드에서 LangChain RAG 및 Ollama 처리 후 JSON 형식 데이터 반환.

- **Python 백엔드 ↔ Ollama API**
  - 요청: 질문과 관련된 데이터를 Ollama AI에 전달.
  - 응답: Ollama에서 생성한 텍스트 결과 반환.

#### 주요 흐름 다이어그램
```
사용자 → 브라우저 → Nginx (index.html) → JavaScript (Axios) → Spring Boot → Python (Flask with LangChain & Ollama)
     ←---------------- 데이터 처리 결과 ------------------------←
```

---

## 3. Python 백엔드 - Ollama 연동 추가

### 3.1. Ollama API 연동 스크립트
#### `ollama_manager.py`
```python
import requests

def query_ollama(prompt, model="default-model"):
    url = f"http://ollama-server:8000/api/query"
    payload = {
        "prompt": prompt,
        "model": model
    }
    response = requests.post(url, json=payload)
    if response.status_code == 200:
        return response.json().get("response", "No response from Ollama")
    else:
        return f"Error: {response.status_code}, {response.text}"
```

### 3.2. Flask 백엔드 수정
#### `app.py`
```python
from flask import Flask, request, jsonify
from chromadb_manager import initialize_chroma, embed_and_store_documents
from ollama_manager import query_ollama

app = Flask(__name__)
vectorstore = initialize_chroma()

@app.route('/query', methods=['POST'])
def handle_query():
    data = request.get_json()
    question = data.get('question', '')

    # Chroma DB 유사도 검색
    results = vectorstore.similarity_search(question, k=3)
    context = "\n".join([doc.page_content for doc in results])

    # Ollama 호출
    answer = query_ollama(prompt=f"Context: {context}\nQuestion: {question}")

    return jsonify(answer=answer, context_results=results)

@app.route('/embed', methods=['POST'])
def embed_documents():
    data = request.get_json()
    documents = data.get('documents', [])
    message = embed_and_store_documents(documents)
    return jsonify(message=message)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

---

## 4. Docker Compose 업데이트

### 4.1. Ollama 서버 추가
#### `docker-compose.yml`
```yaml
version: '3.8'
services:
  frontend:
    build:
      context: ./frontend
    ports:
      - "3000:80"

  backend:
    build:
      context: ./backend
    ports:
      - "8080:8080"

  python-backend:
    build:
      context: ./python-backend
    ports:
      - "5000:5000"

  ollama-server:
    image: ollama/ollama-server
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_API_KEY=your-api-key-here
```

---

## 5. 실행 단계

1. 프로젝트 디렉토리에서 `docker-compose.yml` 파일이 위치한 루트 디렉토리로 이동.
   ```bash
   cd project/
   ```
2. Docker Compose 실행.
   ```bash
   docker-compose up --build
   ```
3. 브라우저에서 다음 URL로 접근:
   - 프론트엔드: `http://localhost:3000`
   - Spring Boot 백엔드: `http://localhost:8080`
   - Python 백엔드: `http://localhost:5000`
   - Ollama 서버: `http://localhost:8000`

---

## 6. 최종 결과

### 6.1. 브라우저에서 확인
1. **로그인 페이지**: `http://localhost:3000`
2. **로그인 후 메인 페이지 이동**: `main.html`
3. **Python 백엔드와 Ollama 연동**: 질문을 보내고 Ollama의 응답 확인.

### 6.2. LangChain & Chroma DB 테스트
1. 문서 임베딩:
   ```bash
   curl -X POST http://localhost:5000/embed -H "Content-Type: application/json" -d '{"documents": ["문서 내용 1", "문서 내용 2"]}'
   ```
2. 질문 처리:
   ```bash
   curl -X POST http://localhost:5000/query -H "Content-Type: application/json" -d '{"question": "문서 내용 관련 질문"}'
   ```

### 6.3. Docker 컨테이너 확인
```bash
docker ps
```
컨테이너가 정상적으로 실행 중인지 확인.

---

## 7. 추가 설정
- **HTTPS**: Let’s Encrypt로 SSL 인증서 추가 가능.
- **404 에러 페이지**: `nginx.conf`에 설정 추가.
