 
 
 # 데이터 출처와 정보

1. 안전모 착용 감지 (출처: https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection)

   * 라벨링 정보 (xml) 2.3MB

      - 헬멧 (helmet), 사람 (person), 머리(head)

      - Annotations in the PASCAL VOC format, saved as XML files.


2. 화재 감지 (출처: AI Hub)

   - 총 1TB 
   - https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=176


3. 문서 데이터 
 
   - SOP, 산업안전보건법 시행규칙 (pdf, word, excel, pptx) 56MB
   - https://drive.google.com/file/d/1djWUtyCiPIOLZ_jbRGenTsPcqXUryypy/view?usp=sharing

4. 데이터 위치 ->  /bucket/work/성훈자료 


#### 데이터 분석 

1. 주요 구성 요소

1. 파일 정보

  - 이미지 파일 이름: hard_hat_workers0.png
  - 이미지 크기: 416x416 (너비 x 높이), 채널 3개 (depth=3)

2. 객체(Object) 정보

  * 두 가지 클래스가 존재

     - helmet (헬멧)
     - head (머리)

  * 각 객체는 bndbox 태그로 경계 상자를 정의

      -  xmin, ymin: 경계 상자의 왼쪽 위 좌표
      -  xmax, ymax: 경계 상자의 오른쪽 아래 좌표


2. 데이터 구조

 * 이미지 정보

```xml
<folder>images</folder>
<filename>hard_hat_workers0.png</filename>
<size>
    <width>416</width>
    <height>416</height>
    <depth>3</depth>
</size>

```

 * 객체 예시

  - helmet 객체의 첫 번째 항목

```xml
<object>
    <name>helmet</name>
    <pose>Unspecified</pose>
    <truncated>0</truncated>
    <occluded>0</occluded>
    <difficult>0</difficult>
    <bndbox>
        <xmin>357</xmin>
        <ymin>116</ymin>
        <xmax>404</xmax>
        <ymax>175</ymax>
    </bndbox>
</object>

```

* head 객체의 예시

```xml
<object>
    <name>head</name>
    <pose>Unspecified</pose>
    <truncated>0</truncated>
    <occluded>0</occluded>
    <difficult>0</difficult>
    <bndbox>
        <xmin>62</xmin>
        <ymin>144</ymin>
        <xmax>83</xmax>
        <ymax>172</ymax>
    </bndbox>
</object>

```


3. 분석 및 활용

* 목적

  - 헬멧(helmet)과 머리(head)를 감지하는 객체 검출 모델 학습에 사용.
  - 주로 안전 모니터링 시스템에서 사용 가능.


* 모델 학습 시 고려 사항

  - 클래스 불균형 여부 확인 (helmet vs head 개수)
  - 작은 객체(작은 경계 상자) 처리 성능 최적화
  - VOC 형식을 YOLO, COCO 등 다른 포맷으로 변환해야 할 경우 전처리 필요





4. PyTorch로 활용

  * PyTorch를 사용하여 PASCAL VOC 형식 데이터로 객체 검출 모델을 학습하려면 다음 단계를 따릅니다

    1. PASCAL VOC 데이터 로드

       - torchvision의 datasets.VOCDetection 또는 XML 파싱 모듈(xml.etree.ElementTree)을 사용.


    2. VOC 형식 데이터 전처리

       - XML 파일에서 필요한 정보를 파싱해 텐서 형태로 변환.
       - 경계 상자를 [xmin, ymin, xmax, ymax] 형태로 정리.

    3. 데이터셋 및 DataLoader 작성

       - PyTorch Dataset 클래스를 작성해 VOC 형식 데이터를 읽고 Tensor로 반환.
       - DataLoader를 사용해 배치 데이터를 효율적으로 처리.

    4. 모델 학습

       - Faster R-CNN, SSD, YOLO 등 모델 활용.
       - torchvision.models.detection에서 사전 학습된 객체 검출 모델 사용 가능.


5. XML에서 필요한 정보 추출 예시 (Python)

```python
import xml.etree.ElementTree as ET

def parse_voc_annotation(xml_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()

    objects = []
    for obj in root.findall('object'):
        name = obj.find('name').text
        bndbox = obj.find('bndbox')
        xmin = int(bndbox.find('xmin').text)
        ymin = int(bndbox.find('ymin').text)
        xmax = int(bndbox.find('xmax').text)
        ymax = int(bndbox.find('ymax').text)

        objects.append({
            'name': name,
            'bbox': [xmin, ymin, xmax, ymax]
        })

    return objects

# Example usage
annotation_file = 'path/to/annotation.xml'
objects = parse_voc_annotation(annotation_file)
print(objects)

```